{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# from deep_nn_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "# layers_dims: array containing dimensions of each layer ex initialize_parameters([5, 4, 3])\n",
    "\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in nn\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l-1], layer_dims[l]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l-1], layer_dims[l]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "#     print([(k, parameters[k].shape) for k, v in parameters.items()])\n",
    "    return parameters\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "#     print('\\nlinear forward')\n",
    "#     print('W', W.shape, 'A', A.shape)\n",
    "    Z = np.dot(W.T, A) + b\n",
    "    \n",
    "#     print('Z', Z.shape)\n",
    "    \n",
    "    assert(Z.shape == (W.shape[1], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z):\n",
    "    t = np.exp(Z)\n",
    "    A = t / np.sum(t, axis=0)\n",
    "    cache = Z\n",
    "\n",
    "    return A, cache\n",
    "    \n",
    "\n",
    "def neuron_activation(A_prev, W, b, activation):\n",
    "    if activation == 'sigmoid':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        # linear cache: A, W, b\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        # activation cache: Z\n",
    "        \n",
    "    elif activation == 'relu':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    elif activation == 'softmax':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "        \n",
    "    assert (A.shape == (W.shape[1], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # // is floor division\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        \n",
    "        A_prev = A\n",
    "        \n",
    "        A, cache = neuron_activation(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], 'relu')\n",
    "        caches.append(cache)\n",
    "\n",
    "    AL, cache = neuron_activation(A, parameters['W' + str(L)], parameters['b' + str(L)], 'softmax')\n",
    "    caches.append(cache)\n",
    "#     print('\\n', AL)\n",
    "#     assert(AL.shape == (1, X.shape[1]))\n",
    "#     assert(AL.shape == (3, X.shape[1])) # should be  (classes x m)\n",
    "\n",
    "    return AL, caches\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "#     cost = (-1/m) * np.sum(Y*np.log(AL) + (1-Y)*np.log(1-AL))\n",
    "    \n",
    "#     cost = np.squeeze(cost)\n",
    "#     assert(cost.shape == ())\n",
    "\n",
    "    cost = (-1/m) * np.sum(Y * np.log(AL))\n",
    "    \n",
    "    return cost\n",
    "    \n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "#     print('dZ.shape', dZ.shape, 'A_prev.shape', A_prev.shape, 'W.shape', W.shape)\n",
    "#     dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "    dW = (1/m) * np.dot(A_prev, dZ.T)\n",
    "    db = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "#     dA_prev = np.dot(W.T, dZ)\n",
    "    dA_prev = np.dot(W, dZ)\n",
    "    \n",
    "#     assert (dA_prev.shape == A_prev.shape)\n",
    "#     assert (dW.shape == W.shape)\n",
    "#     assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    # check here for reverse grad shape bug\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "       \n",
    "    elif activation == 'softmax':\n",
    "        dZ = dA\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "#     Y = Y.reshape(AL.shape)\n",
    "    \n",
    "#     dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) #derivative of cost function\n",
    "    dAL = AL - Y\n",
    "#     print('dAL.shape', dAL.shape)\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"softmax\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+2)], current_cache, \"relu\")\n",
    "        grads[\"dA\" + str(l+1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l+1)] = dW_temp\n",
    "        grads[\"db\" + str(l+1)] = db_temp\n",
    "            \n",
    "    return grads\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2      \n",
    "#     print('\\nupdate parameters')                               \n",
    "#     print([(k, parameters[k].shape) for k, v in parameters.items()])\n",
    "#     print('grads')\n",
    "#     print([(k, grads[k].shape) for k, v in grads.items()])\n",
    "    for l in range(1, L+1):\n",
    "        parameters['W'+str(l)] = parameters['W'+str(l)] - learning_rate * grads['dW'+str(l)]\n",
    "        parameters['b'+str(l)] = parameters['b'+str(l)] - learning_rate * grads['db'+str(l)]\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "def predict(X, y, parameters):\n",
    "    print('X', X.shape, 'Y.shape', Y.shape)\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2\n",
    "    p = np.zeros((y.shape[0], m))\n",
    "    acc = []\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "    print('probas\\n', probas.shape)\n",
    "    # max for each example\n",
    "    # search for index == max\n",
    "    # assign 1 to that class and 0 to the others\n",
    "    for i in range(0, probas.shape[1]):\n",
    "#         print(probas[:, i])\n",
    "        index = np.where(probas[:, i] == np.max(probas[:, i]))\n",
    "        probas[index, i] = 1\n",
    "        zeros = np.where(probas[:, i] != 1)\n",
    "        probas[zeros, i] = 0\n",
    "        if np.where(probas[:,i] == 1) == np.where(y[:,i] ==1):\n",
    "            acc.append(True)\n",
    "#         print(probas[:, i], 'probas')\n",
    "#         print(y[:, i], 'y')\n",
    "#         print(np.where(probas[:,i] == 1) == np.where(y[:,i] ==1))\n",
    "#         probas[:, i][probas != 1] = 0\n",
    "#         print(index)\n",
    "#         print(np.max(probas[:,i]))\n",
    "#         if probas[0, i] > 0.5:\n",
    "#             p[0, i] = 1\n",
    "#         else:\n",
    "#             p[0, i] = 0\n",
    "    print(type(probas))\n",
    "    print(\"Accuracy: \" + str(sum(acc)/m))\n",
    "#     print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layer_dims, learning_rate = .0075, num_iterations = 10, print_cost = False):\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 10000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 10000 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris(True)\n",
    "iris[0].shape[0]\n",
    "X = iris[0].T\n",
    "# X = X[:, :5]\n",
    "Y_cat = iris[1]\n",
    "Y = []\n",
    "for i in Y_cat:\n",
    "    if i==0:\n",
    "        Y.append([1,0,0])\n",
    "    elif i == 1:\n",
    "        Y.append([0,1,0])\n",
    "    elif i == 2:\n",
    "        Y.append([0,0,1])\n",
    "Y = np.array(Y).T\n",
    "# split into training/test\n",
    "# Y = Y[:, :5]\n",
    "# print('X.shape', X.shape)\n",
    "# print('Y.shape', Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "split = np.random.rand(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = split < .67\n",
    "test = split >= .67\n",
    "X_train = X[:, train]\n",
    "Y_train = Y[:, train]\n",
    "X_test = X[:, test]\n",
    "Y_test = Y[:, test]\n",
    "# split correct? Nope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (4, 103) X_test (4, 47)\n",
      "Y_train.shape (3, 103) Y_test (3, 47)\n"
     ]
    }
   ],
   "source": [
    "# create dummy data in three distinct categories of magnitude, X: [3,30]\n",
    "inputs = X.shape[0]\n",
    "m = X.shape[1]\n",
    "layer_dims = [inputs, 3, 4, 5, 3]\n",
    "# layer_dims = [inputs, 3, 8, 5, 3] # best architecture so far\n",
    "# layer_dims = [inputs, 3, 4, 8, 3]\n",
    "# sm = np.random.rand(inputs, m) * -10000\n",
    "# md = np.random.rand(inputs, m) * 1\n",
    "# lg = np.random.rand(inputs, m) * 10000\n",
    "# X = np.hstack((sm, md, lg))\n",
    "\n",
    "# cat1_truth = np.array([[1], [0], [0]]) \n",
    "# cat2_truth = np.array([[0], [1], [0]])\n",
    "# cat3_truth = np.array([[0], [0], [1]])\n",
    "# Y = np.array([[1], [0], [0]])\n",
    "\n",
    "# # Y: [3, 30] for soft max\n",
    "# for i in range(1, X.shape[1]):\n",
    "#     if i < X.shape[1]/3:\n",
    "#         Y = np.hstack((Y, cat1_truth))\n",
    "#     elif i < X.shape[1] * (2/3):\n",
    "#         Y = np.hstack((Y, cat2_truth))\n",
    "#     elif i < X.shape[1]:\n",
    "#         Y = np.hstack((Y, cat3_truth))\n",
    "print('X_train.shape', X_train.shape, 'X_test', X_test.shape)\n",
    "print('Y_train.shape', Y_train.shape, 'Y_test', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.098612\n",
      "Cost after iteration 10000: 1.098612\n",
      "Cost after iteration 20000: 1.098612\n",
      "Cost after iteration 30000: 1.098608\n",
      "Cost after iteration 40000: 0.045596\n",
      "Cost after iteration 50000: 0.039054\n",
      "Cost after iteration 60000: 0.029281\n",
      "Cost after iteration 70000: 0.028365\n",
      "Cost after iteration 80000: 0.027860\n",
      "Cost after iteration 90000: 0.027817\n",
      "Cost after iteration 100000: 0.027792\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(X, Y, layer_dims, .1, 110000, True)\n",
    "# cost <= 6.794738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (4, 47) Y.shape (3, 150)\n",
      "probas\n",
      " (3, 47)\n",
      "<class 'numpy.ndarray'>\n",
      "Accuracy: 0.9787234042553191\n",
      "p.shape (3, 47)\n"
     ]
    }
   ],
   "source": [
    "p = predict(X_test, Y_test, parameters)\n",
    "print('p.shape', p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
